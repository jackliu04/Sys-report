<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>System Design - System</title>
  <meta name="description" content="">
  <meta name="keywords" content="">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com" rel="preconnect">
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Raleway:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Main CSS File -->
  <link href="assets/css/main.css" rel="stylesheet">

</head>

<body class="system_design-page">

  <header id="header" class="header d-flex align-items-center fixed-top">
    <div class="header-container container-fluid container-xl position-relative d-flex align-items-center justify-content-end">

      <a href="index.html" class="logo d-flex align-items-center me-auto">
        <!-- Uncomment the line below if you also wish to use an image logo -->
        <!-- <img src="assets/img/logo.webp" alt=""> -->
        <h1 class="sitename">Chatlinc</h1>
      </a>

      <nav id="navmenu" class="navmenu">
        <ul>
          <li class="dropdown"><a href="index.html"><span>Home</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="index.html#abstract">Abstract</a></li>
              <li><a href="index.html#features">Features</a></li>
              <li><a href="index.html#video">Video</a></li>
              <li><a href="index.html#project_timeline">Project Timeline</a></li>
              <li><a href="index.html#development_team">Development Team</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="requirements.html"><span>Requirements</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="requirements.html#project_background">Project Background</a></li>
              <li><a href="requirements.html#project_goals">Project Goals</a></li>
              <li><a href="requirements.html#requirements_gathering">Requirements Gathering</a></li>
              <li><a href="requirements.html#personas">Personas</a></li>
              <li><a href="requirements.html#use_cases">Use Cases</a></li>
              <li><a href="requirements.html#moscow">MoSCOW</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="research.html"><span>Research</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="research.html#related_projects_review">Related Projects Review</a></li>
              <li><a href="research.html#technology_review">Technology Review</a></li>
              <li><a href="research.html#references">References</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="ui_design.html"><span>UI Design</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="ui_design.html#design_principles">Design Principles</a></li>
              <li><a href="ui_design.html#sketches">Sketches</a></li>
              <li><a href="ui_design.html#prototype">Prototype</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="system_design.html" class="active"><span>System Design</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="system_design.html#architecture">System Architecture</a></li>
              <li><a href="system_design.html#design_patterns">Design Patterns</a></li>
              <li><a href="system_design.html#api">APIs Definition</a></li>
              <li><a href="system_design.html#multimodal_backend">Multimodal Backend</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="implementation.html"><span>Implementation</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="implementation.html#project_structure">Project structure</a></li>
              <li><a href="implementation.html#features">Features</a></li>
              <li><a href="implementation.html#chat_with_video">Chat with Video</a></li>
              <li><a href="implementation.html#multimodal_rag">Multimodal RAG</a></li>
              <li><a href="implementation.html#geographic_map">Geographic Map</a></li>
              <li><a href="implementation.html#task_management">Task Management</a></li>
            </ul>
          </li>
          </li>
          <li class="dropdown"><a href="testing.html"><span>Testing</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="testing.html#testing_strategy">Testing Strategy</a></li>
              <li><a href="testing.html#unit_testing">Unit Testing</a></li>
              <li><a href="testing.html#integration_testing">Integration Testing</a></li>
              <li><a href="testing.html#user_testing">User Acceptance Testing</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="evaluation.html"><span>Evaluation</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="evaluation.html#achievements">Achievements</a></li>
              <li><a href="evaluation.html#critical_evaluation">Critical Evaluation</a></li>
              <li><a href="evaluation.html#future_work">Future Work</a></li>
            </ul>
          </li>
          <li class="dropdown"><a href="appendices.html"><span>Appendices</span> <i class="bi bi-chevron-down toggle-dropdown"></i></a>
            <ul>
              <li><a href="appendices.html#user_manual">User Manual</a></li>
              <li><a href="appendices.html#deployment_manual">Deployment Manual</a></li>
              <li><a href="appendices.html#legal_statements">Legal Statements</a></li>
              <li><a href="appendices.html#dev_blog">Dev Blog</a></li>
              <li><a href="appendices.html#monthly_videos">Monthly Videos</a></li>
            </ul>
          </li>
        </ul>
        <i class="mobile-nav-toggle d-xl-none bi bi-list"></i>
      </nav>

    </div>
  </header>

  <main class="main">

    <!-- Page Title -->
    <div class="page-title light-background position-relative">
      <div class="container">
        <h1>System Design</h1>
        <nav class="breadcrumbs">
          <ol>

          </ol>
        </nav>
      </div>
    </div><!-- End Page Title -->

   <!-- Architecture Section -->
<section id="architecture" class="about-2 section architecture">

  <!-- Section Title -->
  <div class="container section-title" data-aos="fade-up">
    <h2>System Architecture</h2>
  </div><!-- End Section Title -->

  <div class="container" data-aos="fade-up" data-aos-delay="100">
    <h4><strong>High-Level System Overview</strong></h4>
    <p style="font-size: 20px;">
      The multimodal Retrieval-Augmented Generation (RAG) system employs a client-server architecture, clearly delineating responsibilities into frontend and backend subsystems. These subsystems interact via a standardized RESTful API interface, adhering to modular software engineering best practices. A specialized vector database facilitates efficient storage, indexing, and retrieval of embedding vectors, essential for ensuring high-performance information retrieval and response generation.
    </p>

    <!-- Architecture Diagram -->
    <div class="text-center my-4">
      <img src="./assets/img/architecture/architecture.png" alt="System Architecture Overview" class="img-fluid" style="max-width: 100%; height: auto;" />
    </div>

    <hr class="my-4">

    <h4><strong>Frontend Architecture</strong></h4>
    <p style="font-size: 18px;">
      The <strong>frontend</strong> component is implemented using a Single-Page Application (SPA) architecture based on <strong>React</strong> and <strong>TypeScript</strong>. This structure follows modern web development principles, such as modular component design, reactive state management, and responsive user interfaces.
    </p>
    <ul style="font-size: 18px;">
      <li>Capturing user interactions and query inputs.</li>
      <li>Initiating asynchronous requests to backend services through well-defined API endpoints.</li>
      <li>Dynamically displaying retrieved data and generated responses to users through intuitive, user-friendly interfaces.</li>
    </ul>
    <p style="font-size: 18px;">
      This modular frontend design enhances maintainability, allowing for seamless integration of future features and efficient troubleshooting.
    </p>

    <hr class="my-4">

    <h4><strong>Backend Architecture</strong></h4>
    <p style="font-size: 18px;">
      The backend architecture is designed around a <strong>Flask-based RESTful API</strong>, embracing a microservice-oriented architectural style that emphasizes clear separation of concerns and high cohesion within modules. The backend's primary responsibilities encompass:
    </p>
    <ul style="font-size: 18px;">
      <li><strong>API Request Management:</strong> Receiving, validating, and preprocessing incoming HTTP requests from the frontend subsystem.</li>
      <li><strong>Multimodal Embedding Generation:</strong> Employing sophisticated embedding models, notably <strong>BridgeTower-large</strong>, to encode input data into semantic vector representations.</li>
      <li><strong>Multimodal Inference Engine:</strong> Leveraging <strong>LLaVA-7B</strong> for context-aware multimodal reasoning and response generation based on embedding retrieval results.</li>
      <li><strong>Data Persistence and Retrieval:</strong> Interfacing with a dedicated vector database optimized for high-dimensional similarity search.</li>
    </ul>
    <p style="font-size: 18px;">
      This structured backend leverages layered software architecture principles, facilitating scalability, maintainability, testability, and clearly defined data processing workflows.
    </p>

    <hr class="my-4">

    <h4><strong>Vector Database Layer</strong></h4>
    <p style="font-size: 18px;">
      The <strong>vector database</strong> acts as the critical storage and retrieval engine within the system, optimized for rapid indexing and efficient nearest-neighbor similarity searches across high-dimensional embedding vectors. It utilizes advanced indexing techniques to support real-time retrieval performance, significantly enhancing response speed and accuracy in serving multimodal queries.
    </p>

    <hr class="my-4">

    <h4><strong>Data Flow and Interaction</strong></h4>
    <p style="font-size: 18px;">
      The data processing workflow aligns with standard engineering patterns and consists of clearly defined stages:
    </p>
    <ol style="font-size: 18px;">
      <li><strong>User Input Capture:</strong> Users interact directly with the React frontend, entering queries and selecting input data.</li>
      <li><strong>Structured Communication:</strong> The frontend issues structured HTTP requests to backend RESTful API endpoints.</li>
      <li><strong>Backend Processing Pipeline:</strong>
        <ul>
          <li>Embedding models generate semantic vector embeddings from input data.</li>
          <li>The vector database efficiently executes similarity searches to retrieve relevant embeddings.</li>
          <li>The retrieved embeddings and original query inputs are processed by the multimodal inference engine (LLaVA) to generate a context-sensitive response.</li>
        </ul>
      </li>
      <li><strong>Result Delivery:</strong> The backend packages generated responses into JSON objects and returns them via API responses.</li>
      <li><strong>User Presentation:</strong> The frontend dynamically renders and presents responses, concluding the interaction loop.</li>
    </ol>
  </div>
</section><!-- /Architecture Section -->

<!-- Design Patterns Section -->
<section id="design_patterns" class="design_patterns section">
  <!-- Section Title -->
  <div class="container section-title" data-aos="fade-up">
    <h2>Design Patterns</h2>
  </div><!-- End Section Title -->

  <div class="container" data-aos="fade-up" data-aos-delay="100">
    <p style="font-size: 20px;">
      To enhance code maintainability, scalability, and extensibility, the following software engineering design patterns were strategically employed throughout our multimodal Retrieval-Augmented Generation (RAG) application.
    </p>

    <div class="table-responsive my-4">
      <table class="table table-bordered" style="font-size: 18px;">
        <thead class="table-light">
          <tr>
            <th style="width: 25%;"><strong>Design Pattern</strong></th>
            <th><strong>Usage in the Project</strong></th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Singleton Pattern</strong></td>
            <td>
              The embedding models (<code>BridgeTower</code>, <code>ImageBind</code>) and multimodal inference engine (<code>LLaVA</code>) are implemented as singletons. This ensures only one instance of these heavyweight, resource-intensive components is instantiated during runtime, optimizing resource utilization and maintaining consistent behavior.
            </td>
          </tr>
          <tr>
            <td><strong>Facade Pattern</strong></td>
            <td>
              The backend Flask API acts as a Facade, simplifying interactions between frontend clients and complex backend subsystems (e.g., embedding models, vector databases, inference engines). This pattern hides internal complexities and provides a clear, unified interface.
            </td>
          </tr>
          <tr>
            <td><strong>Strategy Pattern</strong></td>
            <td>
              Different multimedia preprocessing strategies (e.g., handling videos with transcripts, without transcripts, or silent) leverage the Strategy Pattern. This allows the backend to dynamically select suitable strategies based on media type, enhancing flexibility and extensibility.
            </td>
          </tr>
          <tr>
            <td><strong>Observer Pattern</strong></td>
            <td>
              Frontend React components follow the Observer Pattern for state management, responding to asynchronous backend updates. Components observe changes in query results and update the UI automatically, ensuring real-time responsiveness and loose coupling.
            </td>
          </tr>
          <tr>
            <td><strong>Chain of Responsibility Pattern</strong></td>
            <td>
              The backend inference pipeline applies the Chain of Responsibility pattern. Each stage (embedding, retrieval, inference) handles its dedicated task in a structured workflow, enabling modularity, clarity, and easier troubleshooting.
            </td>
          </tr>
        </tbody>
      </table>
    </div>

    <p style="font-size: 18px;">
      Additionally, core software design principles were rigorously followed throughout development:
    </p>

    <ul style="font-size: 18px;">
      <li><strong>Single Responsibility Principle (SRP):</strong> Each class maintains a clear, focused purpose to improve readability and testability.</li>
      <li><strong>Don’t Repeat Yourself (DRY):</strong> Code reuse and modularity are enforced across the codebase to reduce redundancy.</li>
      <li><strong>Refactoring Best Practices:</strong> Proactive cleanup eliminated common code smells such as magic numbers, overly long methods, and tightly coupled logic.</li>
    </ul>
  </div>
</section><!-- /Design Patterns Section -->

<!-- APIs Definition Section -->
<section id="api" class="api section">

  <!-- Section Title -->
  <div class="container section-title" data-aos="fade-up">
    <h2>APIs Definition</h2>
  </div><!-- End Section Title -->

  <div class="container" data-aos="fade-up" data-aos-delay="100">

    <p style="font-size: 20px;">
      This document describes the clearly defined RESTful API endpoints within our system.
    </p>

    <hr class="my-4">

    <h4><strong>1. Chat Interaction (<code>/chat</code>)</strong></h4>
    <p style="font-size: 18px;"><strong>Method:</strong> POST</p>
    <p style="font-size: 18px;"><strong>Description:</strong> Facilitates conversational interactions with multimodal data, supporting user queries accompanied by optional multimedia uploads.</p>
    <p style="font-size: 18px;"><strong>Request (form data):</strong></p>
    <ul style="font-size: 18px;">
      <li><code>query</code> (String, required)</li>
      <li><code>collection_name</code> (String, optional)</li>
      <li><code>retrieve</code> (Boolean/String, optional)</li>
      <li><code>session_id</code> (String, optional)</li>
      <li><code>uploaded_file</code> (File, optional)</li>
    </ul>
    <p style="font-size: 18px;"><strong>Response (JSON):</strong></p>
    <pre><code class="language-json">
{
  "response": "&lt;generated response&gt;",
  "images": ["&lt;base64-encoded image&gt;", ...],
  "audios": [
    {
      "audio": "&lt;base64-encoded audio&gt;",
      "transcript": "&lt;audio transcript&gt;"
    }
  ],
  "session_id": "&lt;session identifier&gt;"
}
    </code></pre>

    <hr class="my-4">

    <h4><strong>2. Upload File with Geolocation (<code>/new_upload</code>)</strong></h4>
    <p style="font-size: 18px;"><strong>Method:</strong> POST</p>
    <p style="font-size: 18px;"><strong>Description:</strong> Allows uploading multimedia files into specified collections, optionally attaching descriptive and geographic metadata.</p>
    <p style="font-size: 18px;"><strong>Request (form data):</strong></p>
    <ul style="font-size: 18px;">
      <li><code>file</code> (File, required)</li>
      <li><code>collection_name</code> (String, required)</li>
      <li><code>description</code> (String, optional)</li>
      <li><code>address</code> (String, optional)</li>
      <li><code>latitude</code> (Float, optional)</li>
      <li><code>longitude</code> (Float, optional)</li>
    </ul>
    <p style="font-size: 18px;"><strong>Response (JSON):</strong></p>
    <pre><code class="language-json">
{
  "status": "success",
  "message": "File 'example.jpg' successfully inserted into collection 'example_collection'."
}
    </code></pre>

    <hr class="my-4">

    <h4><strong>3. Retrieve Collections (<code>/collections</code>)</strong></h4>
    <p style="font-size: 18px;"><strong>Method:</strong> GET</p>
    <p style="font-size: 18px;"><strong>Description:</strong> Returns a list of available collections from the vector database.</p>
    <p style="font-size: 18px;"><strong>Response (JSON):</strong></p>
    <pre><code class="language-json">
{
  "collections": ["collection1", "collection2", ...]
}
    </code></pre>

    <hr class="my-4">

    <h4><strong>4. Geographic Search (<code>/new_geo_search</code>)</strong></h4>
    <p style="font-size: 18px;"><strong>Method:</strong> GET</p>
    <p style="font-size: 18px;"><strong>Description:</strong> Performs geographic-based searches within specified collections using coordinates, addresses, radius, and optional keywords.</p>
    <p style="font-size: 18px;"><strong>Request (query parameters):</strong></p>
    <ul style="font-size: 18px;">
      <li><code>collection_name</code> (String, required)</li>
      <li><code>address</code> (String, optional)</li>
      <li><code>radius</code> (Float, required)</li>
      <li><code>keyword</code> (String, optional)</li>
      <li><code>latitude</code> (Float, optional)</li>
      <li><code>longitude</code> (Float, optional)</li>
    </ul>
    <p style="font-size: 18px;"><strong>Response (JSON):</strong></p>
    <pre><code class="language-json">
{
  "results": [ ... ]
}
    </code></pre>

    <hr class="my-4">

    <h4><strong>5. Generate Geographic Map (<code>/geo_map</code>)</strong></h4>
    <p style="font-size: 18px;"><strong>Method:</strong> GET</p>
    <p style="font-size: 18px;"><strong>Description:</strong> Generates an interactive map displaying geographic search results.</p>
    <p style="font-size: 18px;"><strong>Request (query parameters):</strong></p>
    <ul style="font-size: 18px;">
      <li><code>collection_name</code> (String, required)</li>
      <li><code>address</code> (String, optional)</li>
      <li><code>radius</code> (Float, optional, default: 2km)</li>
      <li><code>keyword</code> (String, optional)</li>
      <li><code>latitude</code> (Float, optional)</li>
      <li><code>longitude</code> (Float, optional)</li>
    </ul>
    <p style="font-size: 18px;"><strong>Response:</strong> Renders interactive HTML page <code>geo_map.html</code>.</p>

    <hr class="my-4">

    <h4><strong>6. Video Upload and Processing (<code>/upload_video</code>)</strong></h4>
    <p style="font-size: 18px;"><strong>Method:</strong> POST</p>
    <p style="font-size: 18px;"><strong>Description:</strong> Handles video downloading, frame extraction, transcript generation, multimodal embedding, and ingestion into the vector database.</p>
    <p style="font-size: 18px;"><strong>Request (form data):</strong></p>
    <ul style="font-size: 18px;">
      <li><code>video_url</code> (String, required)</li>
      <li><code>video_without_language_sound</code> (Boolean/String, optional)</li>
      <li><code>n</code> (Integer, optional, default: 6)</li>
    </ul>
    <p style="font-size: 18px;"><strong>Response (JSON):</strong></p>
    <pre><code class="language-json">
{
  "status": "success",
  "video_path": "&lt;stored video path&gt;"
}
    </code></pre>

    <hr class="my-4">

    <h4><strong>7. List All Uploaded Videos (<code>/all_uploaded_videos</code>)</strong></h4>
    <p style="font-size: 18px;"><strong>Method:</strong> GET</p>
    <p style="font-size: 18px;"><strong>Description:</strong> Lists titles of all videos indexed in the vector database.</p>
    <p style="font-size: 18px;"><strong>Response (JSON):</strong></p>
    <pre><code class="language-json">
{
  "video_titles": ["video1 title", "video2 title", ...]
}
    </code></pre>

    <hr class="my-4">

    <h4><strong>8. Chat with Video Content (<code>/chat_with_video</code>)</strong></h4>
    <p style="font-size: 18px;"><strong>Method:</strong> POST</p>
    <p style="font-size: 18px;"><strong>Description:</strong> Enables conversational interaction with indexed video content, retrieving relevant frames and generating semantic responses.</p>
    <p style="font-size: 18px;"><strong>Request (form data):</strong></p>
    <ul style="font-size: 18px;">
      <li><code>video_title</code> (String, required)</li>
      <li><code>query</code> (String, required)</li>
    </ul>
    <p style="font-size: 18px;"><strong>Response (JSON):</strong></p>
    <pre><code class="language-json">
{
  "response": "&lt;generated textual response&gt;",
  "image": "&lt;retrieved frame path&gt;",
  "image_base64": "&lt;base64-encoded retrieved frame&gt;"
}
    </code></pre>

  </div>
</section><!-- /APIs Definition Section -->

<!-- Multimodal Backend Section -->
<section id="multimodal_backend" class="multimodal_backend section">

  <!-- Section Title -->
  <div class="container section-title" data-aos="fade-up">
    <h2>Multimodal Backend Architecture</h2>
  </div><!-- End Section Title -->

  <div class="container" data-aos="fade-up" data-aos-delay="100">
    <p style="font-size: 20px;">
      The multimodal backend architecture of our system is structured to robustly handle multimodal data retrieval, embedding, and inference tasks, clearly divided into two primary pipelines: <strong>Multimodal Retrieval-Augmented Generation (RAG)</strong> and <strong>Video-based Conversational Retrieval</strong> (Chat with Video). Both pipelines integrate advanced embedding techniques, dedicated vector storage solutions, and sophisticated language-vision inference models to deliver accurate and meaningful responses to user queries.
    </p>
    <hr class="my-4">

    <h4><strong>1. Multimodal Retrieval-Augmented Generation (RAG) Backend Architecture</strong></h4>
    <p style="font-size: 18px;">
      The multimodal RAG backend architecture facilitates intelligent retrieval and inference from multimedia file collections, specifically <strong>images</strong> and <strong>audio files</strong>.
    </p>
      <img src="./assets/img/architecture/structure0.jpg" alt="System Architecture Overview" class="img-fluid" style="max-width: 100%; height: auto;" />

    <h5 style="font-size: 18px;">Data Input and Retrieval:</h5>
    <ul style="font-size: 18px;">
      <li>Multimedia file collections are segmented into two distinct input streams:</li>
      <ul>
        <li><strong>Image Retrieval</strong>: Images uploaded by users.</li>
        <li><strong>Audio Retrieval</strong>: Audio clips uploaded by users.</li>
      </ul>
    </ul>

    <h5 style="font-size: 18px;">Embedding Layer:</h5>
    <ul style="font-size: 18px;">
      <li>The backend leverages the <strong>ImageBind</strong> multimodal embedding model, which transforms images and audio into unified semantic vectors.</li>
      <li>This ensures <strong>cross-modal interoperability</strong>, enabling efficient similarity searches across different media types.</li>
    </ul>

    <h5 style="font-size: 18px;">Vector Database Storage:</h5>
    <ul style="font-size: 18px;">
      <li>Embedding vectors are stored in a dedicated <strong>vector database</strong> optimized for high-speed nearest-neighbor semantic searches.</li>
      <li>This enhances responsiveness for real-time query operations.</li>
    </ul>

    <h5 style="font-size: 18px;">Multimodal Retrieval and Inference:</h5>
    <ul style="font-size: 18px;">
      <li>User queries are embedded via ImageBind and used to query the vector database.</li>
      <li>Retrieved <strong>audio files</strong> are transcribed using the <strong>Whisper</strong> model to enhance semantic richness.</li>
      <li>Results and queries are forwarded to <strong>LLaVA-7B</strong> for context-aware response generation.</li>
    </ul>

    <hr class="my-4">

    <h4><strong>2. Chat with Video Backend Architecture</strong></h4>
    <p style="font-size: 18px;">
      The backend pipeline for video-based conversational retrieval addresses scenarios involving diverse video input types and audio/transcript availability.
    </p>
      <img src="./assets/img/architecture/structure2.jpg" alt="System Architecture Overview" class="img-fluid" style="max-width: 100%; height: auto;" />

    <h5 style="font-size: 18px;">Video Data Preprocessing:</h5>
    <ul style="font-size: 18px;">
      <li><strong>Case 1: Videos with Transcript</strong>
        <ul>
          <li>Frames are extracted via <code>cv2</code>, using available transcripts for indexing.</li>
        </ul>
      </li>
      <li><strong>Case 2: Videos without Transcript</strong>
        <ul>
          <li>Transcripts are generated using the <strong>Whisper ASR</strong> model.</li>
          <li>Frames and transcripts are indexed together to form a searchable context base.</li>
        </ul>
      </li>
      <li><strong>Case 3: Videos without Language Audio</strong>
        <ul>
          <li>No transcripts are generated. Semantic meaning is derived directly from visual features using <strong>LLaVA</strong>.</li>
        </ul>
      </li>
    </ul>

    <h5 style="font-size: 18px;">Multimodal Embedding:</h5>
    <ul style="font-size: 18px;">
      <li><strong>BridgeTower-large-itm-mlm-itc</strong> model embeds both <strong>frames</strong> and <strong>transcripts</strong> into unified semantic vectors.</li>
      <li>This model fuses vision and language using <strong>cross-modal attention</strong>.</li>
    </ul>

    <h5 style="font-size: 18px;">Vector Database Storage:</h5>
    <ul style="font-size: 18px;">
      <li>Embedded frame-text pairs are indexed and stored in a high-performance vector database, supporting semantic retrieval.</li>
    </ul>

    <h5 style="font-size: 18px;">Retrieval and Ranking:</h5>
    <ul style="font-size: 18px;">
      <li>User queries are also embedded through <strong>BridgeTower</strong>.</li>
      <li>Similarity search retrieves the most relevant frames and contextual segments.</li>
    </ul>

    <h5 style="font-size: 18px;">Prompt Processing and Inference：</h5>
    <ul style="font-size: 18px;">
      <li>Retrieved frame-transcript-query triplets are compiled into structured prompts.</li>
      <li>Prompts are passed to <strong>LLaVA-7B</strong> for final response generation.</li>
      <li>Responses are returned to the frontend for rendering.</li>
    </ul>

  </div>
</section><!-- /Multimodal Backend Section -->

  </main>

  <footer id="footer" class="footer position-relative light-background">

    <div class="container footer-top">
      <div class="row gy-4">
        <div class="col-lg-5 col-md-12 footer-about">
          <a href="index.html" class="logo d-flex align-items-center">
            <span class="sitename">Chatlinc</span>
          </a>
          <p>This is the report website of Team 12's Project, in partnership with NTTDATA, for the COMP0016 module.</p>
          <div class="social-links d-flex mt-4">
            <a href="https://github.com/Hao-Hao211/ChatLincs.git"><i class="bi bi-github"></i></a>
          </div>
        </div>

        <div class="col-lg-2 col-6 footer-links">
          <h4>Useful Links</h4>
          <ul>
            <li><a href="index.html#">Home</a></li>
            <li><a href="requirements.html#">Requirements</a></li>
            <li><a href="research.html#">Research</a></li>
            <li><a href="ui_design.html#">UI Design</a></li>
            <li><a href="system_design.html#">System Design</a></li>
          </ul>
        </div>

        <div class="col-lg-2 col-6 footer-links">

          <ul>
            <li><a href="implementation.html#">Implementation</a></li>
            <li><a href="testing.html#">Testing</a></li>
            <li><a href="evaluation.html#">Evaluation</a></li>
            <li><a href="appendices.html#">Appendices</a></li>
          </ul>
        </div>

        <div class="col-lg-3 col-md-12 footer-contact text-center text-md-start">

          <p> </p>
        </div>

      </div>
    </div>

    <div class="container copyright text-center mt-4">
      <p>© <span>Copyright</span> <strong class="px-1 sitename">Chatlinc</strong> <span>All Rights Reserved</span></p>

    </div>

  </footer>

  <!-- Scroll Top -->
  <a href="#" id="scroll-top" class="scroll-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Preloader -->
  <div id="preloader"></div>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>